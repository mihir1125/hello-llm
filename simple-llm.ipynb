{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8761d049-83c5-4539-ab5c-995285a5347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_cohere import ChatCohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4d4352-de27-4d61-9c33-e8c8bce22510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatCohere(model=\"command-r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977496d2-d23f-484f-9784-1116c65817b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04e2f9-3db5-427c-9365-cd1f12327576",
   "metadata": {},
   "source": [
    "# Simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fba4323-85d2-4209-ba37-45436e22fd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nanami Kento wa ii hito da.', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '3c5f5623-96cd-43bf-9727-8454a8d72ced', 'token_count': {'input_tokens': 85, 'output_tokens': 9}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '3c5f5623-96cd-43bf-9727-8454a8d72ced', 'token_count': {'input_tokens': 85, 'output_tokens': 9}}, id='run-18948152-43a1-4057-8546-07d49cd16252-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following sentences into Japanese Romanized\"),\n",
    "    HumanMessage(\"Kento Nanami is a nice person.\")\n",
    "]\n",
    "\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af189c-e9b3-46c3-90cb-3a490593027a",
   "metadata": {},
   "source": [
    "# Using output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e62d7ef2-2fe0-41b3-9f71-ad8ac7271570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nanami Kento wa ii hito da.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser\n",
    "\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd8ef4-72a2-48a9-917c-3031904d6786",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Using prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c02144af-60a9-4f6a-b8d3-0c59b98e8cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into Spanish'), HumanMessage(content='Kento Nanami is a nice person')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Translate the following into {language}\"),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "prompt = prompt_template.invoke({\n",
    "    \"language\": \"Spanish\",\n",
    "    \"text\": \"Kento Nanami is a nice person\",\n",
    "})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a19496-d3a6-4686-8f27-6bc4b9f04b56",
   "metadata": {},
   "source": [
    "<script src=\"https://kit.fontawesome.com/28934d071c.js\" crossorigin=\"anonymous\"></script>\n",
    "<i class=\"fas fa-sticky-note\"></i> Note that the returned value is a `ChatPromptValue` object but models accept messages as well as ChatPromptValue as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bf69aed-d347-4548-b0c2-56e2a6556072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kento Nanami hai ek accha aadmi.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | model | parser\n",
    "\n",
    "chain.invoke({\n",
    "    \"language\": \"Hinglish\",\n",
    "    \"text\": \"Kento Nanami is a nice person\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e42c3-68ba-4f1e-87a8-8e62f39cf40e",
   "metadata": {},
   "source": [
    "# LangServe\n",
    "Refer the main.py file for LangServe implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d64e86-ac4f-4018-a16e-82fc72b7d008",
   "metadata": {},
   "source": [
    "# Using Message Place Holders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ad5223e-6997-41f6-a0b2-ac9ea6ed3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "from langserve.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27dde4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputChat(BaseModel):\n",
    "    \"\"\"Input for the chat endpoints.\"\"\"\n",
    "\n",
    "    messages: List[Union[SystemMessage, HumanMessage, AIMessage]] = Field(\n",
    "        ...,\n",
    "        description = \"The chat messages representing the current conversation.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3208fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()\n",
    "\n",
    "system_template = \"You are a helpful, professional assistant named Cob.\"\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_template),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb97167",
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = InputChat(messages=[HumanMessage(\"Hey, what time are you free?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c9e740e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I apologize for being rude. I was just joking. How's it going, Mark? I hope you're doing well today! Are you up to anything exciting?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = model | parser\n",
    "res = chain.invoke(\n",
    "    [\n",
    "        HumanMessage(\"Hi! I'm Mark.\"),\n",
    "        AIMessage(\"What's up loser\"),\n",
    "        HumanMessage(\"Why are you being rude to me?\")\n",
    "    ]\n",
    ")\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
