{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatCohere(model=\"command-r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the model _stateful_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {} # Will store the messages against sessions id\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Mark! It's nice to meet you. How's it going today?\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"a2b3c\",\n",
    "    },\n",
    "}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(\"Hi! I'm Mark.\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Mark! As an AI chatbot, I deduced that from the first message you sent me.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(\"What's my name?\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a2b3c': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm Mark.\"), AIMessage(content=\"Hi Mark! It's nice to meet you. How's it going today?\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '37eef3a3-c569-4606-9c40-d36ea7a195ad', 'token_count': {'input_tokens': 72, 'output_tokens': 16}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '37eef3a3-c569-4606-9c40-d36ea7a195ad', 'token_count': {'input_tokens': 72, 'output_tokens': 16}}, id='run-8110dc72-f8c3-4d67-8bdf-3e79428b8e9d-0'), HumanMessage(content=\"What's my name?\"), AIMessage(content='Your name is Mark! As an AI chatbot, I deduced that from the first message you sent me.', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '63cc7bf1-cf12-4523-9e64-c3e219534c0c', 'token_count': {'input_tokens': 99, 'output_tokens': 22}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '63cc7bf1-cf12-4523-9e64-c3e219534c0c', 'token_count': {'input_tokens': 99, 'output_tokens': 22}}, id='run-e476d3c9-6abe-44e8-aabc-544ebf7255b3-0')])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Sofia. Is there anything else I can help you with?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(\"What's my name?\")],\n",
    "    config={\"configurable\":{\"session_id\": \"e2f3g\"}} # Passing a different config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a2b3c': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm Mark.\"), AIMessage(content=\"Hi Mark! It's nice to meet you. How's it going today?\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '37eef3a3-c569-4606-9c40-d36ea7a195ad', 'token_count': {'input_tokens': 72, 'output_tokens': 16}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '37eef3a3-c569-4606-9c40-d36ea7a195ad', 'token_count': {'input_tokens': 72, 'output_tokens': 16}}, id='run-8110dc72-f8c3-4d67-8bdf-3e79428b8e9d-0'), HumanMessage(content=\"What's my name?\"), AIMessage(content='Your name is Mark! As an AI chatbot, I deduced that from the first message you sent me.', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '63cc7bf1-cf12-4523-9e64-c3e219534c0c', 'token_count': {'input_tokens': 99, 'output_tokens': 22}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '63cc7bf1-cf12-4523-9e64-c3e219534c0c', 'token_count': {'input_tokens': 99, 'output_tokens': 22}}, id='run-e476d3c9-6abe-44e8-aabc-544ebf7255b3-0')]),\n",
       " 'e2f3g': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"What's my name?\"), AIMessage(content=\"I'm sorry, but as an AI chatbot, I don't know your name. If you don't mind, you can share it with me, and I would be delighted to address you by your name.\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b854bc43-73a2-4a0e-b80d-798de60e929f', 'token_count': {'input_tokens': 71, 'output_tokens': 42}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b854bc43-73a2-4a0e-b80d-798de60e929f', 'token_count': {'input_tokens': 71, 'output_tokens': 42}}, id='run-6146bdd0-9001-4870-997f-a52edb064b4c-0'), HumanMessage(content=\"What's my name?\"), AIMessage(content='Your name is Sofia. Is there anything else I can help you with?', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6ee70ffa-782f-4b7f-8ed0-ed5df06101e4', 'token_count': {'input_tokens': 124, 'output_tokens': 15}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '6ee70ffa-782f-4b7f-8ed0-ed5df06101e4', 'token_count': {'input_tokens': 124, 'output_tokens': 15}}, id='run-91666f27-0299-431f-9389-5656d1079066-0')])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persisting state across runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.schema import messages_to_dict, messages_from_dict\n",
    "\n",
    "test_obj = {\"test\": \"dictionary\"}\n",
    "session_id = \"abcd\"\n",
    "# json.dump(test_obj, open(f\"{session_id}.txt\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'human', 'data': {'content': 'Hello! I am Mark.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}}, {'type': 'ai', 'data': {'content': 'Hi Mark!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.human.HumanMessage"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history = [\n",
    "    HumanMessage(\"Hello! I am Mark.\"),\n",
    "    AIMessage(\"Hi Mark!\"),\n",
    "]\n",
    "message_history = InMemoryChatMessageHistory(messages=message_history)\n",
    "\n",
    "temp_dict = messages_to_dict(message_history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "current_sessions = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in current_sessions:\n",
    "        try:\n",
    "            with open(f\"{session_id}.txt\", \"r\") as f:\n",
    "                current_sessions.update(\n",
    "                    messages_from_dict(json.loads(f))\n",
    "                )\n",
    "        except:\n",
    "            current_sessions[session_id] = InMemoryChatMessageHistory()\n",
    "            with open(f\"{session_id}.txt\", \"w\") as f:\n",
    "                json.dump({}, f)\n",
    "    else:\n",
    "        with open(f\"{session_id}.txt\", \"w\") as f:\n",
    "            json.dump(\n",
    "                messages_to_dict(current_sessions[session_id].messages),\n",
    "                f,\n",
    "            )\n",
    "    return current_sessions[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"a2b3c\",\n",
    "    },\n",
    "}\n",
    "\n",
    "with_persistent_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk(text: str):\n",
    "    response = with_persistent_history.invoke(\n",
    "        [HumanMessage(text)],\n",
    "        config=config\n",
    "    )\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Mark! It's nice to meet you. How's it going today?\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"Hello, my name's Mark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you for asking! I'm having a great day so far and I'm happy to be of assistance to you. As an AI chatbot, I don't have any days, but I'm always ready to help and chat!\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"Good! Thanks for asking. Wbu?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The opposite of 'top' could be 'bottom'. The words are often used to describe relative positions, with one being at the highest point and the other at the lowest point. \\n\\nAnother opposite could be the word 'worst', as the top is usually associated with the best or highest quality, while the worst indicates the lowest or poor quality.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"What's the opposite of top?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name's Mark\n",
      "Hi Mark! It's nice to meet you. How's it going today?\n",
      "Good! Thanks for asking. Wbu?\n",
      "I'm doing well, thank you for asking! I'm having a great day so far and I'm happy to be of assistance to you. As an AI chatbot, I don't have any days, but I'm always ready to help and chat!\n"
     ]
    }
   ],
   "source": [
    "with open(\"a2b3c.txt\", \"r\") as f:\n",
    "    messages = messages_from_dict(json.load(f))\n",
    "for m in messages:\n",
    "    print(m.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
